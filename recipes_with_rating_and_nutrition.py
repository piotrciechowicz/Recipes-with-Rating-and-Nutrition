# -*- coding: utf-8 -*-
"""Recipes with Rating and Nutrition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10t6UG59gA5-eSCgZU2X9skvh28q17fM3
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import display
import seaborn as sns

"""#Przygotowanie danych"""

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/epi_r.csv')
df.head()

# Wybór zmiennych do analizy

df_2 = df.iloc[:, 1:6]
df_2.head()
df_2.shape

# Sprawdzenie wierszy NaN

df_2.isnull().sum()

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy = 'mean')
df_2_clean = imputer.fit_transform(df_2)
df_2_clean = pd.DataFrame(data = df_2_clean, index = df_2.index, columns = df_2.columns)

df_2_clean = df_2_clean[df_2_clean['calories']<1500]
df_2_clean = df_2_clean[df_2_clean['protein']<50]
df_2_clean = df_2_clean[df_2_clean['fat']<75]
df_2_clean = df_2_clean[df_2_clean['sodium']<1500]

data = df_2_clean
y = df_2_clean.iloc[:, [0]]
X = df_2_clean.iloc[:,1:6]
df_2_clean

"""#Analiza danych"""

# Zestawienie podstawowych paramtrów statystycznych

df_2_clean.describe()

# Wykres korelacji zmiennych

corr = df_2_clean.corr()
sns.heatmap(np.abs(corr))

# Wniosek: Brak korelacji liniowejzmiennej objaśnianej względem zmiennych objaśniających

"""##Hipoteza 1

Lepszym modelem będzie drzewo decyzyjne
"""

sns.distplot(df_2_clean.rating, bins =4)

sns.distplot(df_2_clean.calories, bins =20)

sns.distplot(df_2_clean.fat, bins =20)

sns.distplot(df_2_clean.protein, bins =20)

sns.distplot(df_2_clean.sodium, bins =20)

df_3 = df_2_clean
df_3['Rate'] = np.round(df_3['rating'])
df_3.head()

sns.barplot(x='Rate', y='calories', data=df_3)

#wniosek: wysoka zawartość kalorii wpływa na wysoką ocenę

sns.barplot(x='Rate', y='protein', data=df_3)

#wniosek: wysoka zawartość białka wpływa na wysoką ocenę

sns.barplot(x='Rate', y='fat', data=df_3)

#wniosek: wysoka zawartość tłuszczu wpływa na wysoką ocenę, ale nie za duzo

sns.barplot(x='Rate', y='sodium', data=df_3)

#wniosek: wysoka zawartość sodu wpływa na wysoką ocenę

# Zestawienie zbiorcze

melted_df_3 = pd.melt(df_3, 
                    id_vars = ['rating', 'Rate'], 
                    var_name='stat'
                    )

sns.barplot(x='stat', y='value', data=melted_df_3, hue = 'Rate')
plt.legend(bbox_to_anchor=(1,1), loc=2)

"""##Hipoteza 2

Im wyższa wartość zmiennych objaśniających tym wyższa ocena

#Model

##Dane
"""

data.head()

X.head()

y.head()

"""##TrainTestSplit"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)

X_train.shape

"""## Standaryzacja"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)
X_sc = scaler.transform(X_train)
X_sc

X_sc_df = pd.DataFrame(data = X_sc,
                           columns = X_train.columns,
                           index = X_train.index)
X_sc_df

"""##Regresja liniowa"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
print(f"R_2 score: {lin_reg.score(X_val, y_val)}")
print('\n')
mse_train = mean_squared_error(y_train, lin_reg.predict(X_train), squared=False)
print(f"MSE_train: {mse_train}")
mse_test = mean_squared_error(y_test, lin_reg.predict(X_test), squared=False)
print(f"MSE_test {mse_test}")

"""##Regresyjne lasy losowe"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.datasets import make_regression

rfr_reg = RandomForestRegressor(n_estimators = 100, 
                                max_depth=10, 
                                min_samples_split = 3, 
                                min_samples_leaf = 1,
                                random_state=42, 
                                oob_score=True)
rfr_reg.fit(X_train, y_train)

print(f"R_2 score: {rfr_reg.score(X_val, y_val)}")
print('\n')
mse_train = mean_squared_error(y_train, rfr_reg.predict(X_train), squared=False)
print(f"MSE_train: {mse_train}")
mse_test = mean_squared_error(y_test, rfr_reg.predict(X_test), squared=False)
print(f"MSE_test {mse_test}")

"""#Wnioski"""

#Lepszym modelm jest: Regresyjne lasy losowe
print(f"R_2 score: {rfr_reg.score(X_test, y_test)}")